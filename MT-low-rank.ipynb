{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, Sampler\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as albu\n",
    "import os, glob, sys, shutil\n",
    "import cv2, itertools, random, pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from collections import Counter\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sklearn\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_process\n",
    "import utils\n",
    "IMAGE_FOLDER = \"/data/tcga/512dense/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(123)\n",
    "# torch.manual_seed(123)\n",
    "# torch.cuda.manual_seed_all(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./data/APC_TP53_KRAS_PIK3CA_FAT4.pkl\" , \"rb\") as fp:\n",
    "    cohort_gene_dict = pickle.load(fp)\n",
    "track_name = cohort_gene_dict['track_name']\n",
    "del cohort_gene_dict['track_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 226, 1: 211})\n"
     ]
    }
   ],
   "source": [
    "# track_name_idx = [0, 1, 2]\n",
    "track_name_idx = track_name.index('TP53')\n",
    "patient_ids = list(cohort_gene_dict.keys())\n",
    "patient_cls = list(cohort_gene_dict.values())\n",
    "patient_cls = np.array(patient_cls)\n",
    "# 先做 APC\n",
    "patient_cls = patient_cls[:, track_name_idx]\n",
    "lookup = dict(zip(patient_ids, patient_cls))\n",
    "print(Counter(patient_cls))\n",
    "\n",
    "del cohort_gene_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train patient:Counter({0: 150, 1: 141})\n",
      "# valid patient:Counter({0: 76, 1: 70})\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)\n",
    "for train_index, test_index in skf.split(patient_ids, patient_cls):\n",
    "    train_patient = [patient_ids[i] for i in train_index]\n",
    "    valid_patient = [patient_ids[i] for i in test_index]\n",
    "    train_cls = [lookup[i] for i in train_patient]\n",
    "    valid_cls = [lookup[i] for i in valid_patient]\n",
    "    print(\"# train patient:{}\\n# valid patient:{}\".format(Counter(train_cls), Counter(valid_cls)))\n",
    "    del train_cls, valid_cls\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train images:1016542\n",
      "# valid images:445538\n",
      "# train images:Counter({1: 540708, 0: 475834})\n",
      "# valid images:Counter({1: 228670, 0: 216868})\n",
      "# train npys:(0: 224, 1: 255)\n",
      "# valid npys:(0: 109, 1: 122)\n"
     ]
    }
   ],
   "source": [
    "train_images, valid_images, train_lookup, valid_lookup, train_npys = utils.data.load_data(train_patient=train_patient, valid_patient=valid_patient, \\\n",
    "                                                        patient_label_dict = lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(x, **kwargs):\n",
    "    x = x/255.\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "def get_preprocessing():\n",
    "    _transform = [\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)\n",
    "\n",
    "def get_training_augmentation():\n",
    "    test_transform = [\n",
    "        albu.RandomCrop(224, 224),\n",
    "        albu.Flip(),\n",
    "        albu.RandomRotate90(),\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.ElasticTransform(p=1),\n",
    "                albu.GridDistortion(p=1),\n",
    "                albu.OpticalDistortion(p=1)\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "        albu.ShiftScaleRotate(border_mode=0, value=0),\n",
    "        albu.IAAAdditiveGaussianNoise(),\n",
    "        albu.GaussianBlur(),\n",
    "        albu.OneOf(\n",
    "            [\n",
    "#                 albu.RandomBrightnessContrast(p=1),\n",
    "#                 albu.HueSaturationValue(p=1),\n",
    "                albu.HueSaturationValue(hue_shift_limit=60, sat_shift_limit=90, val_shift_limit=60, p=1),\n",
    "                albu.ColorJitter(p=1),\n",
    "            ], \n",
    "            p=0.9,\n",
    "        ),\n",
    "        \n",
    "    ]\n",
    "    return albu.Compose(test_transform)\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    test_transform = [\n",
    "#         albu.Resize(224, 224),\n",
    "    ]\n",
    "    return albu.Compose(test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalDataset(Dataset): \n",
    "    def __init__(self, root_dir = IMAGE_FOLDER, images = None, augmentation = None, preprocessing = None):\n",
    "        self.root = root_dir\n",
    "        self.images = images\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "                    \n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.images[index]\n",
    "        svs_name = img_name.split(\"_\")[0]\n",
    "        patient_name = svs_name[:12]\n",
    "        target = lookup[patient_name]\n",
    "        \n",
    "        full_path = os.path.join(self.root, svs_name, img_name+\".jpg\")\n",
    "        image = data_process.wsi_utils.vips_get_image(full_path)\n",
    "        \n",
    "        if self.augmentation:\n",
    "            img = self.augmentation(image = image)['image']\n",
    "        if self.preprocessing:\n",
    "            img = self.preprocessing(image = img)['image']\n",
    "        return img, target, img_name\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset): \n",
    "    def __init__(self, root_dir, mode, images = None, lookup_table = None, \n",
    "                 augmentation = None, preprocessing = None, probability=[]): \n",
    "        self.root = root_dir\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.labels = lookup_table\n",
    "        self.images = images\n",
    "        self.probability = probability\n",
    "                    \n",
    "    def __getitem__(self, index):\n",
    "        if self.mode=='labeled':\n",
    "            img_name = self.images[index]\n",
    "            svs_name = img_name.split(\"_\")[0]\n",
    "            target = self.labels[img_name] \n",
    "            prob = self.probability[index]\n",
    "            \n",
    "            full_path = os.path.join(self.root, svs_name, img_name+\".jpg\")\n",
    "            image = data_process.wsi_utils.vips_get_image(full_path)\n",
    "            \n",
    "            img1 = self.augmentation(image = image)['image']\n",
    "            img2 = self.augmentation(image = image)['image']\n",
    "            img1 = self.preprocessing(image = img1)['image']\n",
    "            img2 = self.preprocessing(image = img2)['image']\n",
    "            return img1, img2, target, prob, img_name  \n",
    "        \n",
    "        elif self.mode=='unlabeled':\n",
    "            img_name = self.images[index]\n",
    "            svs_name = img_name.split(\"_\")[0]\n",
    "            \n",
    "            full_path = os.path.join(self.root, svs_name, img_name+\".jpg\")\n",
    "            image = data_process.wsi_utils.vips_get_image(full_path)\n",
    "            \n",
    "            img1 = self.augmentation(image = image)['image']\n",
    "            img2 = self.augmentation(image = image)['image']\n",
    "            img1 = self.preprocessing(image = img1)['image']\n",
    "            img2 = self.preprocessing(image = img2)['image']\n",
    "            return img1, img2, img_name\n",
    "        \n",
    "        elif self.mode=='warmup':\n",
    "            img_name = self.images[index]\n",
    "            svs_name = img_name.split(\"_\")[0]\n",
    "            target = self.labels[img_name]\n",
    "            \n",
    "            full_path = os.path.join(self.root, svs_name, img_name+\".jpg\")\n",
    "            image = data_process.wsi_utils.vips_get_image(full_path)  \n",
    "            \n",
    "            img1 = self.augmentation(image = image)['image']\n",
    "            img2 = self.augmentation(image = image)['image']\n",
    "            img1 = self.preprocessing(image = img1)['image']\n",
    "            img2 = self.preprocessing(image = img2)['image']\n",
    "            return img1, img2, target, img_name\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrapperLoader():  \n",
    "    def __init__(self, batch_size=32, num_workers=16, root_dir=IMAGE_FOLDER):\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "    def run(self, mode, labeled_images=[], unlabeled_images=[], clean_probability=None, filtered_lookup=None):\n",
    "        if mode=='warmup':\n",
    "            class_index = [[],[]]\n",
    "            for index, name in enumerate(train_images):\n",
    "                class_index[train_lookup[name]].append(index)\n",
    "            if len(class_index[1]) > len(class_index[0]):\n",
    "                primary_idnex, secondary_index = class_index[1], class_index[0]\n",
    "            else:\n",
    "                primary_idnex, secondary_index = class_index[0], class_index[1]\n",
    "            # undersampling\n",
    "            primary_idnex = random.sample(primary_idnex, len(secondary_index))\n",
    "            data_sampler = utils.sampler.TwoStreamBatchSampler(primary_idnex, secondary_index, hyperParam[\"bs\"],hyperParam[\"bs\"]//2, is_random=True)\n",
    "            \n",
    "            warmup_dataset = CustomDataset(root_dir=self.root_dir, mode=\"warmup\", \n",
    "                                        images=train_images, lookup_table=train_lookup,\n",
    "                                        augmentation=get_training_augmentation(), preprocessing=get_preprocessing()) \n",
    "            trainloader = DataLoader(\n",
    "                dataset=warmup_dataset, \n",
    "                batch_sampler=data_sampler,\n",
    "                num_workers=self.num_workers,\n",
    "                pin_memory=True)\n",
    "            \n",
    "            return trainloader\n",
    "                                     \n",
    "        elif mode=='train':\n",
    "            labeled_prob = [clean_probability[i] for i in labeled_images]\n",
    "            class_index = [[],[]]\n",
    "            for index, name in enumerate(labeled_images):\n",
    "                class_index[filtered_lookup[name]].append(index)\n",
    "            data_sampler = utils.sampler.TwoStreamBatchSampler(class_index[1], class_index[0], hyperParam[\"bs\"],hyperParam[\"bs\"]//2, is_random=True)\n",
    "            labeled_dataset = CustomDataset(root_dir=self.root_dir, mode=\"labeled\",\n",
    "                                            images=labeled_images, lookup_table=filtered_lookup, probability=labeled_prob,\n",
    "                                            augmentation=get_training_augmentation(), preprocessing=get_preprocessing())            \n",
    "            labeled_trainloader = DataLoader(\n",
    "                dataset=labeled_dataset, \n",
    "                batch_sampler=data_sampler,\n",
    "                num_workers=self.num_workers,\n",
    "                pin_memory=True)        \n",
    "            \n",
    "            unlabeled_dataset =  CustomDataset(root_dir=self.root_dir, mode=\"unlabeled\",\n",
    "                                               images=unlabeled_images, lookup_table=filtered_lookup,\n",
    "                                               augmentation=get_training_augmentation(), preprocessing=get_preprocessing())                   \n",
    "            unlabeled_trainloader = DataLoader(\n",
    "                dataset=unlabeled_dataset, \n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=True,\n",
    "                num_workers=self.num_workers,\n",
    "                pin_memory=True)\n",
    "            \n",
    "            return labeled_trainloader, unlabeled_trainloader\n",
    "        \n",
    "        elif mode==\"test\":\n",
    "            test_dataset = EvalDataset(root_dir=self.root_dir, images=valid_images, \n",
    "                                       augmentation=get_training_augmentation(), preprocessing=get_preprocessing()) \n",
    "            test_loader = DataLoader(\n",
    "                test_dataset, \n",
    "                batch_size=self.batch_size*2, \n",
    "                shuffle=False, \n",
    "                num_workers=self.num_workers, \n",
    "                pin_memory=True)\n",
    "            return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_dataset = CustomDataset(root_dir=IMAGE_FOLDER, mode=\"warmup\", \n",
    "#             images=train_images, lookup_table=train_lookup,\n",
    "#             augmentation=get_training_augmentation(), preprocessing=get_preprocessing())  \n",
    "# plt.figure(figsize=(20,10))\n",
    "# for i in range(5):\n",
    "#     import random\n",
    "#     rand = random.randint(0, len(all_dataset))\n",
    "#     s_img, t_img, cls, patch_name = all_dataset[rand]\n",
    "#     plt.subplot(2, 5, i+1)\n",
    "#     plt.title(cls)\n",
    "#     plt.imshow(s_img.transpose(1, 2, 0))\n",
    "    \n",
    "#     plt.subplot(2, 5, i+6)\n",
    "#     plt.title(cls)\n",
    "#     plt.imshow(t_img.transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_ema_variables(model, ema_model, alpha, global_step):\n",
    "    # Use the true average until the exponential average is more correct\n",
    "    alpha = min(1 - 1 / (global_step + 1), alpha)\n",
    "    for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n",
    "        ema_param.data.mul_(alpha).add_(1 - alpha, param.data)\n",
    "\n",
    "def sigmoid_rampup(current, rampup_length):\n",
    "    \"\"\"Exponential rampup from https://arxiv.org/abs/1610.02242\"\"\"\n",
    "    if rampup_length == 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        current = np.clip(current, 0.0, rampup_length)\n",
    "        phase = 1.0 - current / rampup_length\n",
    "        return float(np.exp(-5.0 * phase * phase))\n",
    "    \n",
    "def _format_logs(logs):\n",
    "    str_logs = ['{} - {:.4}'.format(k, v) for k, v in logs.items()]\n",
    "    s = ', '.join(str_logs)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup(epoch, model, ema_model, optimizer, trainloader):\n",
    "    global GLOBAL_STEP\n",
    "    model.train()\n",
    "    ema_model.train()\n",
    "    \n",
    "    logs = {}\n",
    "    cls_loss_meter = utils.meter.AverageValueMeter()\n",
    "    ema_cls_loss_meter = utils.meter.AverageValueMeter()\n",
    "    consistency_loss_meter = utils.meter.AverageValueMeter()\n",
    "    kl_loss_meter = utils.meter.AverageValueMeter()\n",
    "    rank_regular_meter = utils.meter.AverageValueMeter()\n",
    "    total_loss_meter = utils.meter.AverageValueMeter()\n",
    "    \n",
    "    metrics_meters = {}\n",
    "    for metric in metrics:\n",
    "        metrics_meters[\"Student_\"+metric.__name__] = utils.meter.AverageValueMeter()\n",
    "        metrics_meters[\"Teacher_\"+metric.__name__] = utils.meter.AverageValueMeter()\n",
    "    \n",
    "    with tqdm(trainloader, desc=\"train\", file=sys.stdout) as iterator:\n",
    "        for i, (x, ema_x, y, image_names) in enumerate(iterator):\n",
    "            x, ema_x, y = x.to(DEVICE), ema_x.to(DEVICE), y.to(DEVICE) # b*3*w*h, b*3*w*h, b*1, \n",
    "\n",
    "            pred, mu_logvar = model(x)\n",
    "            ema_pred, ema_mu_logvar = ema_model(ema_x)\n",
    "            ema_pred = torch.autograd.Variable(ema_pred.detach().data, requires_grad = False)\n",
    "            \n",
    "            \"\"\" cls loss\"\"\"\n",
    "            cls_loss = cls_criterion(pred, y)\n",
    "            ema_cls_loss = cls_criterion(ema_pred, y)\n",
    "            \n",
    "            \"\"\" LDDG \"\"\"\n",
    "            kl_loss = kl_criterion(mu_logvar[:, 0], mu_logvar[:, 1])\n",
    "            feature = mu_logvar[:, 2]\n",
    "            feature = feature[torch.randperm(len(feature))]\n",
    "            \n",
    "            rank_regular_value = rank_regular(feature)\n",
    "            \n",
    "            \"\"\" Consistency ramp-up from https://arxiv.org/abs/1610.02242 \"\"\"\n",
    "            consistency_weight = 100. * sigmoid_rampup(epoch, hyperParam[\"warm_up\"])\n",
    "            consistency_loss = consistency_criterion(pred, ema_pred)\n",
    "            \n",
    "            \"\"\" total loss\"\"\"\n",
    "            loss = cls_loss + consistency_weight*consistency_loss + 0.01*kl_loss + 0.001*rank_regular_value\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            \"\"\" update ema model \"\"\"\n",
    "            ema_update_weight = 0.9 if (GLOBAL_STEP <= 10) else 0.99\n",
    "            update_ema_variables(model, ema_model, ema_update_weight, GLOBAL_STEP)\n",
    "            GLOBAL_STEP += 1\n",
    "\n",
    "            # update loss logs\n",
    "            cls_loss_meter.add(cls_loss.item())\n",
    "            ema_cls_loss_meter.add(ema_cls_loss.item())\n",
    "            consistency_loss_meter.add(consistency_loss.item())\n",
    "            kl_loss_meter.add(kl_loss.item())\n",
    "            rank_regular_meter.add(rank_regular_value.item())\n",
    "            total_loss_meter.add(loss.item())\n",
    "            \n",
    "            loss_logs = {\"total loss\": total_loss_meter.mean, \\\n",
    "                         \"Student_\" + cls_criterion.__name__: cls_loss_meter.mean, \\\n",
    "                         \"Teacher_\" + cls_criterion.__name__: ema_cls_loss_meter.mean, \\\n",
    "                         consistency_criterion.__name__: consistency_loss_meter.mean, \\\n",
    "                         kl_criterion.__name__: kl_loss_meter.mean, \\\n",
    "                         \"rank regular\": rank_regular_meter.mean,\n",
    "                        }\n",
    "            logs.update(loss_logs)\n",
    "\n",
    "            # update metrics logs\n",
    "            for metric_fn in metrics:\n",
    "                metric_value = metric_fn(pred, y).cpu().detach().numpy()\n",
    "                metrics_meters[\"Student_\"+metric_fn.__name__].add(metric_value)\n",
    "                metric_value = metric_fn(ema_pred, y).cpu().detach().numpy()\n",
    "                metrics_meters[\"Teacher_\"+metric_fn.__name__].add(metric_value)\n",
    "            metrics_logs = {k: v.mean for k, v in metrics_meters.items()}\n",
    "            logs.update(metrics_logs)\n",
    "\n",
    "            s = _format_logs(logs)\n",
    "            iterator.set_postfix_str(s)\n",
    "            \n",
    "    writer.add_scalar(\"{}/{}\".format(\"Total Loss\", \"train\"), total_loss_meter.mean, epoch)\n",
    "    writer.add_scalar(\"{}/{}\".format(cls_criterion.__name__, \"train\"), cls_loss_meter.mean, epoch)\n",
    "    writer.add_scalar(\"{}/{}\".format(cls_criterion.__name__, \"train_ema\"), ema_cls_loss_meter.mean, epoch)\n",
    "    writer.add_scalar(\"{}/{}\".format(consistency_criterion.__name__, \"train\"), consistency_loss_meter.mean, epoch)\n",
    "    writer.add_scalar(\"{}/{}\".format(kl_criterion.__name__, \"train\"), kl_loss_meter.mean, epoch)\n",
    "    writer.add_scalar(\"{}/{}\".format(\"rank regular\", \"train\"), rank_regular_meter.mean, epoch)\n",
    "    writer.add_scalar(\"{}/{}\".format(metrics[0].__name__, \"train\"), metrics_meters[\"Student_\"+metrics[0].__name__].mean, epoch)\n",
    "    writer.add_scalar(\"{}/{}\".format(metrics[0].__name__, \"train_ema\"), metrics_meters[\"Teacher_\"+metrics[0].__name__].mean, epoch)\n",
    "    \n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch,model,ema_model,optimizer,labeled_trainloader,unlabeled_trainloader):\n",
    "    global GLOBAL_STEP\n",
    "    model.train()\n",
    "    ema_model.train() # mean-teacher source code setting train() \n",
    "\n",
    "    logs = {}\n",
    "    cls_loss_meter = utils.meter.AverageValueMeter()\n",
    "    ema_cls_loss_meter = utils.meter.AverageValueMeter()\n",
    "    consistency_loss_meter = utils.meter.AverageValueMeter()\n",
    "    kl_loss_meter = utils.meter.AverageValueMeter()\n",
    "    rank_regular_meter = utils.meter.AverageValueMeter()\n",
    "    total_loss_meter = utils.meter.AverageValueMeter()\n",
    "    \n",
    "    with tqdm(labeled_trainloader, desc=\"train\", file=sys.stdout) as iterator:\n",
    "        for batch_idx, (inputs_x, inputs_x2, labels_x, w_x, image_names) in enumerate(iterator):      \n",
    "            try:\n",
    "                inputs_u, inputs_u2, unlabeled_image_names = unlabeled_train_iter.next() # b*3*h*w, b*3*h*w\n",
    "            except:\n",
    "                unlabeled_train_iter = iter(unlabeled_trainloader)\n",
    "                inputs_u, inputs_u2, unlabeled_image_names = unlabeled_train_iter.next()                 \n",
    "            batch_size = inputs_x.size(0)\n",
    "            \n",
    "            inputs_x, inputs_x2, labels_x, w_x = inputs_x.to(DEVICE), inputs_x2.to(DEVICE), labels_x.to(DEVICE), w_x.to(DEVICE)\n",
    "            inputs_u, inputs_u2 = inputs_u.to(DEVICE), inputs_u2.to(DEVICE)\n",
    "            \n",
    "            model_inputs = torch.cat([inputs_x, inputs_u], dim=0) # 2b*3*h*w\n",
    "            ema_model_inputs =  torch.cat([inputs_x2, inputs_u2], dim=0) # 2b*3*h*w\n",
    "                        \n",
    "            pred, mu_logvar = model(model_inputs)\n",
    "            ema_pred, ema_mu_logvar = ema_model(ema_model_inputs)\n",
    "            ema_pred = torch.autograd.Variable(ema_pred.detach().data, requires_grad = False)\n",
    "            \n",
    "            \"\"\" only labeled-data calculate CE loss \"\"\"\n",
    "            cls_loss = cls_criterion(pred[:batch_size], labels_x[:batch_size])\n",
    "            ema_cls_loss = cls_criterion(ema_pred[:batch_size], labels_x[:batch_size])\n",
    "            \n",
    "            \"\"\" LDDG \"\"\"\n",
    "            kl_loss = kl_criterion(mu_logvar[:, 0], mu_logvar[:, 1])\n",
    "            feature = mu_logvar[:, 2]\n",
    "            feature = feature[torch.randperm(len(feature))]\n",
    "            rank_regular_value = rank_regular(feature)\n",
    "            \n",
    "            \"\"\"Consistency ramp-up from https://arxiv.org/abs/1610.02242\"\"\" \n",
    "            consistency_weight = 100. * sigmoid_rampup(epoch, hyperParam[\"warm_up\"])\n",
    "            consistency_loss = consistency_criterion(pred, ema_pred)\n",
    "            \n",
    "            \"\"\" total loss\"\"\"\n",
    "            loss = cls_loss + consistency_weight*consistency_loss + 0.01*kl_loss + 0.001*rank_regular_value\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            \"\"\" update ema model \"\"\"\n",
    "            ema_update_weight = 0.9 if (GLOBAL_STEP <= 10) else 0.99\n",
    "            update_ema_variables(model, ema_model, ema_update_weight, GLOBAL_STEP)\n",
    "            GLOBAL_STEP += 1\n",
    "            \n",
    "            # update loss logs\n",
    "            cls_loss_meter.add(cls_loss.item())\n",
    "            ema_cls_loss_meter.add(ema_cls_loss.item())\n",
    "            consistency_loss_meter.add(consistency_loss.item())\n",
    "            kl_loss_meter.add(kl_loss.item())\n",
    "            rank_regular_meter.add(rank_regular_value.item())\n",
    "            total_loss_meter.add(loss.item())\n",
    "            \n",
    "            loss_logs = {\"total loss\": total_loss_meter.mean, \\\n",
    "                         \"Student_\" + cls_criterion.__name__: cls_loss_meter.mean, \\\n",
    "                         \"Teacher_\" + cls_criterion.__name__: ema_cls_loss_meter.mean, \\\n",
    "                         consistency_criterion.__name__: consistency_loss_meter.mean, \\\n",
    "                         kl_criterion.__name__: kl_loss_meter.mean, \\\n",
    "                         \"rank regular\": rank_regular_meter.mean,\n",
    "                        }\n",
    "            logs.update(loss_logs)\n",
    "            \n",
    "            s = _format_logs(logs)\n",
    "            iterator.set_postfix_str(s)\n",
    "            \n",
    "    writer.add_scalar(\"{}/{}\".format(\"Total Loss\", \"train\"), total_loss_meter.mean, epoch)\n",
    "    writer.add_scalar(\"{}/{}\".format(cls_criterion.__name__, \"train\"), cls_loss_meter.mean, epoch)\n",
    "    writer.add_scalar(\"{}/{}\".format(cls_criterion.__name__, \"train_ema\"), ema_cls_loss_meter.mean, epoch)\n",
    "    writer.add_scalar(\"{}/{}\".format(consistency_criterion.__name__, \"train\"), consistency_loss_meter.mean, epoch)\n",
    "    writer.add_scalar(\"{}/{}\".format(kl_criterion.__name__, \"train\"), kl_loss_meter.mean, epoch)\n",
    "    writer.add_scalar(\"{}/{}\".format(\"rank regular\", \"train\"), rank_regular_meter.mean, epoch)\n",
    "    writer.add_scalar(\"{}/{}\".format(metrics[0].__name__, \"train\"), metrics_meters[\"Student_\"+metrics[0].__name__].mean, epoch)\n",
    "    writer.add_scalar(\"{}/{}\".format(metrics[0].__name__, \"train_ema\"), metrics_meters[\"Teacher_\"+metrics[0].__name__].mean, epoch)\n",
    "    \n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(epoch, ema_model, valid_loader):\n",
    "    ema_model.eval()\n",
    "    logs = {}\n",
    "    ema_cls_loss_meter = utils.meter.AverageValueMeter()\n",
    "    metrics_meters = {metric.__name__: utils.meter.AverageValueMeter() for metric in metrics}\n",
    "    \n",
    "    patient_preds = {}\n",
    "    with tqdm(valid_loader, desc=\"validate\", file=sys.stdout) as iterator:\n",
    "        for i, (ema_x, y, image_names) in enumerate(iterator):\n",
    "            ema_x, y = ema_x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                ema_pred = ema_model(ema_x)\n",
    "                ema_cls_loss = cls_criterion(ema_pred, y)\n",
    "\n",
    "            # update loss logs\n",
    "            ema_cls_loss_meter.add(ema_cls_loss.item())\n",
    "            loss_logs = {cls_criterion.__name__: ema_cls_loss_meter.mean}\n",
    "            logs.update(loss_logs)\n",
    "\n",
    "            # update metrics logs\n",
    "            for metric_fn in metrics:\n",
    "                metric_value = metric_fn(ema_pred, y).cpu().detach().numpy()\n",
    "                metrics_meters[metric_fn.__name__].add(metric_value)\n",
    "            metrics_logs = {k: v.mean for k, v in metrics_meters.items()}\n",
    "            logs.update(metrics_logs)\n",
    "            \n",
    "            _, outputs = torch.max(ema_pred, 1)  \n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            for pid, p in zip(image_names, outputs):\n",
    "                pid = pid[:12]\n",
    "                if pid not in patient_preds:\n",
    "                    patient_preds[pid] = [0,0]\n",
    "                patient_preds[pid][p] += 1\n",
    "            \n",
    "            s = _format_logs(logs)\n",
    "            iterator.set_postfix_str(s)\n",
    "    \n",
    "    y_pred, y_gt = [], []\n",
    "    for key, values in patient_preds.items():\n",
    "        y_gt.append(lookup[key])\n",
    "        y_pred.append(values[1]/(values[0]+values[1]))\n",
    "    auc = sklearn.metrics.roc_auc_score(y_gt, y_pred)\n",
    "    precision, recall, _thresholds = sklearn.metrics.precision_recall_curve(y_gt, y_pred)\n",
    "    aupr = sklearn.metrics.auc(recall, precision)\n",
    "    print(\"\\n| Test Epoch #%d\\t AUC: %.2f AUPR: %2f\\n\" %(epoch,auc,aupr))  \n",
    "    \n",
    "    logs.update({\"AUC\": auc})\n",
    "    logs.update({\"AUPR\": aupr})\n",
    "    \n",
    "    writer.add_scalar(\"{}/{}\".format(cls_criterion.__name__, \"valid_ema\"), ema_cls_loss_meter.mean, epoch)\n",
    "    writer.add_scalar(\"{}/{}\".format(\"Patient AUC\", \"valid\"), auc, epoch)\n",
    "    writer.add_scalar(\"{}/{}\".format(\"Patient AUPR\", \"valid\"), aupr, epoch)\n",
    "    writer.add_scalar(\"{}/{}\".format(metrics[0].__name__, \"valid\"), metrics_meters[metrics[0].__name__].mean, epoch)\n",
    "    \n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_train(epoch, ema_model):\n",
    "    global filtered_lookup\n",
    "    global ensemble_prediction\n",
    "    \n",
    "    ema_model.eval()\n",
    "    with tqdm(train_npys, desc=\"eval train\", file=sys.stdout) as iterator:\n",
    "        for idx, npy in enumerate(iterator):\n",
    "            x_y_pairs = np.load(npy)\n",
    "            svs_name = npy.split(\"/\")[-1][:-4]\n",
    "            # only GT=1, filter noise\n",
    "            if lookup[svs_name[:12]] == 1:\n",
    "                eval_images = [\"{}_{}_{}\".format(svs_name, x, y) for x, y in x_y_pairs]\n",
    "\n",
    "                eval_dataset = EvalDataset(\n",
    "                                images=eval_images,\n",
    "                                augmentation=get_validation_augmentation(),\n",
    "                                preprocessing=get_preprocessing())\n",
    "                eval_loader = DataLoader(eval_dataset, batch_size=hyperParam[\"bs\"]*4, shuffle=False, num_workers=16, pin_memory=True)\n",
    "                losses = np.array([])\n",
    "                patch_names = []\n",
    "                for batch_idx, (x, y, image_names) in enumerate(eval_loader):\n",
    "                    x, y = x.cuda(), y.cuda()\n",
    "                    with torch.no_grad():\n",
    "                        pred = ema_model(x) \n",
    "                        loss = filter_CE(pred, y)  # reduction = \"none\"\n",
    "                    assert loss.size()[0] == x.size()[0], \"reduction should be none\"\n",
    "                    loss = loss.detach().cpu().numpy()\n",
    "                    image_names = list(image_names)\n",
    "                    pred = pred.detach().cpu().numpy()\n",
    "                    for pid, p in zip(image_names, pred): # prediction ensemble\n",
    "                        ensemble_prediction[pid] = 0.1*ensemble_prediction[pid]+0.9*p\n",
    "                    losses = np.concatenate((losses, loss))\n",
    "                    patch_names.extend(image_names)    \n",
    "                    \n",
    "                GMM_filter_noisy(patch_names, losses)\n",
    "    \n",
    "    print(\"filtered: {}\".format(Counter(list(filtered_lookup.values()))))\n",
    "    \n",
    "    labeled_images = []\n",
    "    unlabeled_images = []\n",
    "    for key, value in filtered_lookup.items():\n",
    "        if value == -1:\n",
    "            unlabeled_images.append(key)\n",
    "        else:\n",
    "            labeled_images.append(key)\n",
    "    \n",
    "    return labeled_images, unlabeled_images\n",
    "\n",
    "def SELF_filter_noisy(patch_names):\n",
    "    global filtered_lookup\n",
    "    global ensemble_prediction\n",
    "    global train_lookup\n",
    "    for pid in patch_names:\n",
    "        agreement = np.argmax(ensemble_prediction[pid])\n",
    "        if agreement != train_lookup[pid]:\n",
    "            filtered_lookup[pid] = -1\n",
    "    return\n",
    "\n",
    "def GMM_filter_noisy(patch_names=None, patch_losses=None):\n",
    "    global filtered_lookup\n",
    "    global ensemble_prediction\n",
    "    \"\"\" normalize loss\"\"\"\n",
    "    patch_losses = (patch_losses - patch_losses.min())/(patch_losses.max() - patch_losses.min() + 1e-10)\n",
    "    \"\"\" fit a two-component GMM to the loss \"\"\"\n",
    "    gmm = GaussianMixture(n_components=2,max_iter=10,tol=1e-2,reg_covar=5e-4)\n",
    "    input_losses = patch_losses.reshape(-1,1)\n",
    "    \n",
    "    gmm.fit(input_losses)\n",
    "    gmm_prob = gmm.predict_proba(input_losses) \n",
    "    gmm_prob = gmm_prob[:,gmm.means_.argmin()]\n",
    "    gmm_pred = (gmm_prob > hyperParam[\"p_threshold\"])     \n",
    "\n",
    "    labeled_index = gmm_pred.nonzero()[0]\n",
    "    unlabeled_index = (1-gmm_pred).nonzero()[0]\n",
    "    \"\"\" set unlabeled \"\"\"\n",
    "    for index in unlabeled_index:\n",
    "        filtered_lookup[patch_names[index]] = -1\n",
    "    for pid, p in zip(patch_names, gmm_prob):\n",
    "        clean_probability[pid] = p\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxMeanSquareLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    @property\n",
    "    def __name__(self):\n",
    "        return \"SoftmaxMeanSquareLoss\"\n",
    "    def forward(self, y_pred, y_gt):\n",
    "        y_pred = F.softmax(y_pred, dim = 1)\n",
    "        y_gt = F.softmax(y_gt, dim = 1)\n",
    "        return nn.MSELoss()(y_pred, y_gt) \n",
    "    \n",
    "class KLLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    @property\n",
    "    def __name__(self):\n",
    "        return \"KLGuassianLoss\"\n",
    "    def forward(self, mu, logvar):\n",
    "        kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return kl_loss \n",
    "\n",
    "\n",
    "class LowRank(nn.Module):\n",
    "    def __init__(self, num_class = 2):\n",
    "        super().__init__()\n",
    "        self.num_class = num_class\n",
    "    @property\n",
    "    def __name__(self):\n",
    "        return \"low rank\"\n",
    "    def forward(self, x):\n",
    "        try:\n",
    "            U, S, V = torch.svd(x)\n",
    "        except: # torch.svd may have convergence issues for GPU and CPU.\n",
    "            U, S, V = torch.svd(x + 1e-4*x.mean()*torch.rand(l, h))\n",
    "            \n",
    "        return S[self.num_class] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoders.resnet import resnet18, Flatten\n",
    "from encoders.shufflenetv2 import shufflenet_v2_x1_0\n",
    "class VANet(nn.Module):\n",
    "    def __init__(self, num_class = 2, feature_dim = 80, input_size = 512):\n",
    "        super(VANet, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.feature_dim = feature_dim\n",
    "        self.feature_size = input_size//32\n",
    "        #self.encoder = resnet18()\n",
    "        self.encoder = shufflenet_v2_x1_0()\n",
    "        \"\"\"remove avgpool, flatten, fc \"\"\"\n",
    "        self.encoder = torch.nn.Sequential(*(list(self.encoder.children())[:-3])) # resnet b*512*7*7\n",
    "        \n",
    "        self.mu = nn.Sequential(\n",
    "            nn.Conv2d(1024, 256, (self.feature_size, self.feature_size), stride=1),\n",
    "            nn.ReLU(),\n",
    "            Flatten(),\n",
    "            nn.Linear(256, self.feature_dim),\n",
    "        )\n",
    "        self.logvar = nn.Sequential(\n",
    "            nn.Conv2d(1024, 256, (self.feature_size, self.feature_size), stride=1),\n",
    "            nn.ReLU(),\n",
    "            Flatten(),\n",
    "            nn.Linear(256, self.feature_dim),\n",
    "        )\n",
    "        self.cls = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "            Flatten(),\n",
    "            nn.Linear(1024, self.num_class)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        if self.training:\n",
    "            mu = self.mu(x)\n",
    "            logvar = self.logvar(x)\n",
    "            feature = self.reparameterization(mu, logvar)\n",
    "            x = self.cls(x)\n",
    "            return x, torch.stack([mu, logvar, feature], dim=1)\n",
    "        else:\n",
    "            x = self.cls(x)\n",
    "            return x\n",
    "    \n",
    "    def reparameterization(self, mu, logvar):\n",
    "        std = torch.exp(logvar / 2)\n",
    "        sampled_z = torch.normal(mu, std)\n",
    "        z = sampled_z * std + mu\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    from utils.weight_init import weight_init\n",
    "    model = VANet(num_class=2, input_size=224)\n",
    "    model.apply(weight_init)\n",
    "    model = model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperParam = {\n",
    "    \"num_class\": 2,\n",
    "#     \"T\": 0.5,\n",
    "#     \"alpha\": 4,\n",
    "#     \"lambda_u\": 20,\n",
    "#     \"p_threshold\": 0.5, # clean label threshold tao\n",
    "#     \"ensemble_momentum\": 0.9,\n",
    "    \"num_epochs\": 30,\n",
    "    \"lr_cosine\":15,\n",
    "    \"warm_up\": 0,\n",
    "    \"bs\": 32\n",
    "}\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "GLOBAL_STEP = 0 \n",
    "\n",
    "loader = WrapperLoader(batch_size=hyperParam[\"bs\"], num_workers=16)\n",
    "valid_loader = loader.run('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" for noisy label\"\"\"\n",
    "# ensemble_prediction = {key: 0 for key, value in train_lookup.items()} # initialize ensemble predictions of all samples\n",
    "# clean_probability = {key: 1 for key, value in train_lookup.items()}\n",
    "# \"\"\" for filter noisy label \"\"\"\n",
    "# filtered_lookup = copy.deepcopy(train_lookup) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/log_folder/demo/demo/2021-02-03-10_AUPRLoss_TP53_MT_shufflenetv2_LDDG\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pytz import timezone    \n",
    "taipei = timezone('Asia/Taipei')\n",
    "taipei_time = datetime.now(taipei)\n",
    "current_time = taipei_time.strftime('%Y-%m-%d-%H')\n",
    "\n",
    "model_name = current_time + \"_AUPRLoss_TP53_MT_shufflenetv2_LDDG\"\n",
    "log_folder_name = os.path.join('/data/log_folder/demo/demo/',model_name)\n",
    "writer = SummaryWriter(log_dir=log_folder_name, flush_secs=3)\n",
    "print(log_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Building net\n"
     ]
    }
   ],
   "source": [
    "print('| Building net')\n",
    "model = create_model()\n",
    "ema_model = create_model()\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)\n",
    "warm_up_with_cosine_lr = lambda epoch: (epoch+1) / hyperParam[\"warm_up\"] if epoch < hyperParam[\"warm_up\"] \\\n",
    "    else 0.5 * ( math.cos((epoch - hyperParam[\"warm_up\"]) /(hyperParam[\"lr_cosine\"] - hyperParam[\"warm_up\"]) * math.pi) + 1)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR( optimizer, lr_lambda=warm_up_with_cosine_lr)\n",
    "\n",
    "# warm_up_with_step_lr\n",
    "# gamma = 0.1; stepsize = 1\n",
    "# warm_up_with_step_lr = lambda epoch: (epoch+1) / hyperParam[\"warm_up\"] if epoch < hyperParam[\"warm_up\"] \\\n",
    "#     else gamma**( ((epoch - hyperParam[\"warm_up\"]) /(15 - hyperParam[\"warm_up\"]))//stepsize*stepsize)\n",
    "\n",
    "\n",
    "# cls_criterion = utils.losses.CrossEntropy().cuda()\n",
    "cls_criterion = utils.global_objective.AUCPRHingeLoss(num_classes=2).cuda()\n",
    "\n",
    "consistency_criterion = SoftmaxMeanSquareLoss().cuda()\n",
    "kl_criterion = KLLoss().cuda()\n",
    "rank_regular = LowRank().cuda()\n",
    "\n",
    "filter_CE = utils.losses.CrossEntropy(reduction='none').cuda()\n",
    "metrics = [utils.metrics.Fscore()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff7466355f8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test\n",
    "a_ = []\n",
    "for i in range(30):\n",
    "    lr = warm_up_with_cosine_lr(i)*1e-3\n",
    "    a_.append(lr)\n",
    "plt.plot(a_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "swa_model = AveragedModel(ema_model)\n",
    "swa_scheduler = SWALR(optimizer, swa_lr=0.005)\n",
    "swa_start = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/30], LR 0.001000\n",
      "Warmup\n",
      "train:   0%|          | 3/29739 [00:06<38:18:16,  4.64s/it, total loss - 8.289, Student_AUPRLoss - 1.912, Teacher_AUPRLoss - 1.947, SoftmaxMeanSquareLoss - 0.06164, KLGuassianLoss - 2.749, rank regular - 185.4, Student_fscore - 0.1739, Teacher_fscore - 6.25e-09]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:760.)\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  46%|████▌     | 13637/29739 [40:33<1:28:47,  3.02it/s, total loss - 0.5275, Student_AUPRLoss - 0.4927, Teacher_AUPRLoss - 0.5288, SoftmaxMeanSquareLoss - 0.0002456, KLGuassianLoss - 0.2141, rank regular - 8.131, Student_fscore - 9.003e-05, Teacher_fscore - 6.25e-09]"
     ]
    }
   ],
   "source": [
    "max_value = 0.5\n",
    "for epoch in range(0, 30):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr = param_group['lr']\n",
    "    print(\"Epoch [{}/{}], LR {:.6f}\".format(epoch, hyperParam[\"num_epochs\"], lr))\n",
    "    writer.add_scalar(\"{}\".format(\"Learning Rate\"), lr, epoch)\n",
    "    \n",
    "#     if epoch < hyperParam[\"warm_up\"]:    \n",
    "#         warmup_trainloader = loader.run('warmup')\n",
    "#         print('Warmup')\n",
    "#         warmup(epoch, model, ema_model, optimizer, warmup_trainloader)    \n",
    "#     else:         \n",
    "#         labeled_images, unlabeled_images = eval_train(epoch, ema_model) \n",
    "#         print('Train')\n",
    "#         labeled_trainloader, unlabeled_trainloader = loader.run('train', \n",
    "#                                             labeled_images=labeled_images, unlabeled_images=unlabeled_images,\n",
    "#                                             clean_probability=clean_probability, filtered_lookup=filtered_lookup)\n",
    "#         train(epoch, model, ema_model, optimizer,labeled_trainloader, unlabeled_trainloader)\n",
    "    \n",
    "    print('Warmup')\n",
    "    warmup_trainloader = loader.run('warmup')\n",
    "    warmup(epoch, model, ema_model, optimizer, warmup_trainloader)  \n",
    "    \n",
    "    if epoch > swa_start:\n",
    "        swa_model.update_parameters(model)\n",
    "        swa_scheduler.step()\n",
    "    else:\n",
    "        scheduler.step()\n",
    "    \n",
    "    print('Valid')\n",
    "    logs = validate(epoch,ema_model,valid_loader)\n",
    "    \n",
    "    if max_value < logs[\"AUC\"]:\n",
    "        max_value = logs[\"AUC\"]\n",
    "    save_path = \"/data/weight/gene/tp53/{}_EMA_epoch_{}_AUROC_{:.4f}\".format(model_name, epoch, logs[\"AUC\"])\n",
    "    torch.save(ema_model.state_dict(), save_path)\n",
    "    save_path = \"/data/weight/gene/tp53/{}_epoch_{}_AUROC_{:.4f}\".format(model_name, epoch, logs[\"AUC\"])\n",
    "    torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# swa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.optim.swa_utils.update_bn(valid_loader, swa_model, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate: 100%|██████████| 6962/6962 [21:37<00:00,  5.37it/s, CrossEntropyLoss - 0.6893, fscore - 0.4062]   \n",
      "\n",
      "| Test Epoch #29\t AUC: 0.61 AUPR: 0.698114\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CrossEntropyLoss': 0.6893467143738762,\n",
       " 'fscore': 0.4062457853962077,\n",
       " 'AUC': 0.6104116222760291,\n",
       " 'AUPR': 0.6981144739359819}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(epoch,swa_model,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/data/weight/gene/tp53/{}_SWA_epoch_{}_AUROC_{:.4f}\".format(model_name, epoch, 0.6104)\n",
    "torch.save(swa_model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ema_model.eval()\n",
    "swa_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using_npy = \"/data/tcga/kmeans_cluster_32/\"\n",
    "using_npy = \"/data/tcga/512denseTumor/\"\n",
    "valid_npy_pos = []\n",
    "valid_npy_neg = []\n",
    "for npy in sorted(glob.glob(os.path.join(using_npy, \"*.npy\"))):    \n",
    "    patient = npy.split(\"/\")[-1][:12]\n",
    "    if patient in valid_patient:\n",
    "        if lookup[patient] == 1:\n",
    "            valid_npy_pos.append(npy)\n",
    "        else:\n",
    "            valid_npy_neg.append(npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TT_positive_pred = {}\n",
    "with tqdm(valid_npy_pos, desc=\"test\", file=sys.stdout) as iterator:\n",
    "    for npy in iterator:\n",
    "        svs_name = npy.split(\"/\")[-1][:-4]\n",
    "        x_y_pairs = np.load(npy)\n",
    "        image_names = [\"{}_{}_{}\".format(svs_name, x, y) for x, y in x_y_pairs]\n",
    "\n",
    "        test_dataset = EvalDataset(\n",
    "            images = image_names,\n",
    "            augmentation = get_validation_augmentation(),\n",
    "            preprocessing = get_preprocessing(),\n",
    "        )\n",
    "        test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=16, pin_memory=True)\n",
    "        all_predictions = np.array([])\n",
    "        svs_pred = [0,0]\n",
    "        for images, labels, patch_name in test_loader:\n",
    "            with torch.no_grad():\n",
    "#                 predictions = ema_model.forward(images.cuda())\n",
    "                predictions = swa_model.forward(images.cuda())\n",
    "            \n",
    "            predictions = torch.softmax(predictions, dim = 1)\n",
    "            predictions = predictions[:, 1].detach().cpu().numpy()\n",
    "            all_predictions = np.concatenate((all_predictions, predictions))\n",
    "            for p in predictions:\n",
    "                if p > 0.5:\n",
    "                    svs_pred[1] += 1\n",
    "                else:\n",
    "                    svs_pred[0] += 1\n",
    "        y_pred = svs_pred[1]/(svs_pred[0]+svs_pred[1])\n",
    "        if svs_name[:12] not in TT_positive_pred:\n",
    "            TT_positive_pred[svs_name[:12]] = []\n",
    "        TT_positive_pred[svs_name[:12]].append(y_pred)\n",
    "        \n",
    "        title = \"{}_gt={}_pred={:.4f}\".format(svs_name, lookup[svs_name[:12]], y_pred)\n",
    "        data_process.stitch.stitch(wsi_name = svs_name, x_y_pairs = x_y_pairs, preds = all_predictions, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TT_negative_pred = {}\n",
    "with tqdm(valid_npy_neg, desc=\"test\", file=sys.stdout) as iterator:\n",
    "    for npy in iterator:\n",
    "        svs_name = npy.split(\"/\")[-1][:-4]\n",
    "        x_y_pairs = np.load(npy)\n",
    "        image_names = [\"{}_{}_{}\".format(svs_name, x, y) for x, y in x_y_pairs]\n",
    "\n",
    "        test_dataset = EvalDataset(\n",
    "            images = image_names,\n",
    "            augmentation = get_validation_augmentation(),\n",
    "            preprocessing = get_preprocessing(),\n",
    "        )\n",
    "        test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=16, pin_memory=True)\n",
    "        all_predictions = np.array([])\n",
    "        svs_pred = [0,0]\n",
    "        for images, labels, patch_name in test_loader:\n",
    "            with torch.no_grad():\n",
    "#                 predictions = ema_model.forward(images.cuda())\n",
    "                predictions = swa_model.forward(images.cuda())\n",
    "            predictions = torch.softmax(predictions, dim = 1)\n",
    "            predictions = predictions[:, 1].detach().cpu().numpy()\n",
    "            all_predictions = np.concatenate((all_predictions, predictions))\n",
    "            for p in predictions:\n",
    "                if p > 0.5:\n",
    "                    svs_pred[1] += 1\n",
    "                else:\n",
    "                    svs_pred[0] += 1\n",
    "        y_pred = svs_pred[1]/(svs_pred[0]+svs_pred[1])\n",
    "        if svs_name[:12] not in TT_negative_pred:\n",
    "            TT_negative_pred[svs_name[:12]] = []\n",
    "        TT_negative_pred[svs_name[:12]].append(y_pred)\n",
    "        \n",
    "        title = \"{}_gt={}_pred={:.4f}\".format(svs_name, lookup[svs_name[:12]], y_pred)\n",
    "        data_process.stitch.stitch(wsi_name = svs_name, x_y_pairs = x_y_pairs, preds = all_predictions, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [np.amax(values) for key, values in TT_positive_pred.items()] \\\n",
    "        + [np.amax(values) for key, values in TT_negative_pred.items()]\n",
    "gt = [1]*len(TT_positive_pred) + [0]*len(TT_negative_pred)\n",
    "print(roc_auc_score(gt, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
